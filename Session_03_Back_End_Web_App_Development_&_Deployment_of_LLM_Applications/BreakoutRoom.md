# ğŸš€ Breakout Room #1: Build & Deploy Your First Backend â€“ *Hot Mess Coach*

Welcome! In this breakout room we switch from frontend to backendâ€”students will build a **Python FastAPI application**, integrate **LLM-powered chat**, analyze documents (PDF, CSV), and deploy the full backend to **Vercel**.

---

## ğŸ“š Table of Contents

- [What Is This Demo?](#what-is-this-demo)
- [Prerequisites](#prerequisites)
- [Overview](#overview)
- [Step 1: Create Your FastAPI "Hot Mess Coach" App ğŸ](#step-1-create-your-fastapi-hot-mess-coach-app-)
- [Step 2: Run Locally ğŸƒ](#step-2-run-locally-)
- [Step 3: Add GitFlow + Cursor Rules ğŸ“](#step-3-add-gitflow--cursor-rules-)
- [Step 4: Deploy FastAPI Backend to Vercel â˜ï¸](#step-4-deploy-fastapi-backend-to-vercel-ï¸)
- [Step 5: Add LLM Chat to Hot Mess Coach ğŸ¤–](#step-5-add-llm-chat-to-hot-mess-coach-)
- [Step 6: Context Engineering + Document Analysis (PDF/CSV) ğŸ“„â¡ï¸ğŸ§ ](#step-6-context-engineering--document-analysis-pdfcsv-ï¸)
- [Advanced Module: Chunking + Uploading CSV/PDF + Local Testing + Re-deploy ğŸš€](#advanced-module-chunking--uploading-csvpdf--local-testing--re-deploy-)
- [ğŸ—ï¸ Activity #1](#ï¸-activity-1)

---

## Prerequisites

- Python 3.10+
- Cursor IDE
- GitHub account
- Vercel account
- Install Vercel CLI:
  ```bash
  npm install -g vercel
  ```

---

## ğŸ¤ Breakout Room #1

A full hands-on backend session using FastAPI + LLM + document analysis + deployment.

---

# What Is This Demo?

Students will:

- Build a FastAPI backend
- Use Cursor agents with GitFlow rules
- Deploy to Vercel
- Add LLM chat
- Add PDF/CSV document analysis
- Learn context engineering
- Learn chunking + JSON structuring
- Test locally + redeploy

---

# ğŸ“ Step 1: Add GitFlow + Cursor Rules

Add:

- `gitflow_rules.md`
- `cursor_rules.md`

Teach feature branches, PRs, merging into `develop`, releasing to `main`.

---

# ğŸƒ Step 2: Run Locally

Visit:
- http://localhost:8000
- http://localhost:8000/docs

---
# ğŸ Step 3: Create Your FastAPI "Hot Mess Coach" App

```bash
mkdir hot-mess-coach
cd hot-mess-coach
uv venv
source .venv/bin/activate
pip install fastapi uvicorn python-multipart
```

Create `main.py` with a basic FastAPI app + `/analyze` endpoint.

Run locally:
```bash
uvicorn main:app --reload
```

---

# â˜ï¸ Step 4: Deploy FastAPI Backend to Vercel

Create `vercel.json`:

```json
{
  "builds": [{ "src": "main.py", "use": "@vercel/python" }],
  "routes": [{ "src": "/(.*)", "dest": "main.py" }]
}
```

Deploy:

```bash
vercel
```

---

# ğŸ¤– Step 5: Add LLM Chat to Hot Mess Coach

Add `/chat` endpoint:

- Input: `{"message": "..."}`
- Output: LLM-powered response
- Add persona: â€œHot Mess Coachâ€

Add system instructions for context engineering.

---

# ğŸ“„â¡ï¸ğŸ§  Step 6: Context Engineering + Document Analysis

Add endpoints:

### `/upload-csv`
- Accept CSV â†’ convert to JSON â†’ summarize via LLM

### `/upload-pdf`
- Extract text â†’ send structured JSON to LLM

---

# ğŸš€ Advanced Module: Chunking + Local Testing + Re-deploy

Chunking helper:

```python
def chunk_text(text, size=1500):
    return [text[i:i+size] for i in range(0, len(text), size)]
```

Test in a notebook â†’ integrate into FastAPI â†’ run locally â†’ deploy again.

---

# ğŸ—ï¸ Activity #1

Now it's your turn to experiment and get creative! Use this time to practice what you've learned and explore the tools.

**Experiment with Backend Customization:**

- Create a new .py file containing your FastAPI application
- Add an LLM-powered chatbot endpoint
- use .env for API-KEY
- Create feature branches for each new addition
- Implement extra features (new routes, utilities, or enhancements)
- Open and merge pull requests following GitFlow best practices
- Deploy your updated backend to Vercel



---

Enjoy building your backend AI app! ğŸ‰
